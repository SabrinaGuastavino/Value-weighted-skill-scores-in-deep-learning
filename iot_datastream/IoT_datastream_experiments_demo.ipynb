{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on IoT data stream\n",
    "## Sabrina Guastavino, guastavino@dima.unige.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas\n",
    "import pickle\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import time\n",
    "import numpy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPool1D\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from collections import deque\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# user-defined libraries\n",
    "import utilities.training_metrics as tm\n",
    "\n",
    "\n",
    "from utilities.utilities_datastream import create_timeseries, compute_cm_tss, compute_weight_cm_tss, \\\n",
    "optimize_time_weighted_tss_split, optimize_threshold_skill_scores,compute_weight_cm_tss_threshold_split, \\\n",
    "compute_cm_tss_threshold, predict_ensemble, flatten, scale,predict,select_best_patience_on_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc yes in data:  27.771484138795717\n",
      "perc yes in device 0:  1.9248518216204393\n",
      "perc yes in device 1:  56.50411058295055\n",
      "perc yes in device 2:  1.601020043426535\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "#original dataset\n",
    "data = pd.read_csv('data/iot_telemetry_data.csv')\n",
    "#***\n",
    "# drop the duplicates and keep the first occurence only, modify the dataframe\n",
    "data.drop_duplicates(inplace=True, keep=\"first\")\n",
    "# verification that there are no duplicates\n",
    "data[data.duplicated(keep=False) == True]\n",
    "#***\n",
    "print('perc yes in data: ',data['light'].values.sum()*100./len(data))\n",
    "print('perc yes in device 0: ', data[data['device']=='00:0f:00:70:91:0a']['light'].values.sum()*100./len(data[data['device']=='b8:27:eb:bf:9d:51']))\n",
    "print('perc yes in device 1: ', data[data['device']=='1c:bf:ce:15:ec:4d']['light'].values.sum()*100./len(data[data['device']=='b8:27:eb:bf:9d:51']))\n",
    "print('perc yes in device 2: ', data[data['device']=='b8:27:eb:bf:9d:51']['light'].values.sum()*100./len(data[data['device']=='b8:27:eb:bf:9d:51']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device\n",
       "00:0f:00:70:91:0a    111815\n",
       "1c:bf:ce:15:ec:4d    105913\n",
       "b8:27:eb:bf:9d:51    187443\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each device show the number of samples\n",
    "data.groupby('device').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b8:27:eb:bf:9d:51', '00:0f:00:70:91:0a', '1c:bf:ce:15:ec:4d'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#*** 3 device\n",
    "data['device'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>device</th>\n",
       "      <th>co</th>\n",
       "      <th>humidity</th>\n",
       "      <th>light</th>\n",
       "      <th>lpg</th>\n",
       "      <th>motion</th>\n",
       "      <th>smoke</th>\n",
       "      <th>temp</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.594512e+09</td>\n",
       "      <td>b8:27:eb:bf:9d:51</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>2020-07-12 00:01:34.385974407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.594512e+09</td>\n",
       "      <td>00:0f:00:70:91:0a</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013275</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>2020-07-12 00:01:34.735567570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.594512e+09</td>\n",
       "      <td>b8:27:eb:bf:9d:51</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>50.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020475</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>2020-07-12 00:01:38.073572636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.594512e+09</td>\n",
       "      <td>1c:bf:ce:15:ec:4d</td>\n",
       "      <td>0.004403</td>\n",
       "      <td>76.800003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007023</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018628</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2020-07-12 00:01:39.589146137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.594512e+09</td>\n",
       "      <td>b8:27:eb:bf:9d:51</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>50.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020448</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>2020-07-12 00:01:41.761234999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405179</th>\n",
       "      <td>1.595203e+09</td>\n",
       "      <td>00:0f:00:70:91:0a</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>75.300003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>2020-07-20 00:03:33.162014961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405180</th>\n",
       "      <td>1.595203e+09</td>\n",
       "      <td>b8:27:eb:bf:9d:51</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>False</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>2020-07-20 00:03:33.576560736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405181</th>\n",
       "      <td>1.595203e+09</td>\n",
       "      <td>1c:bf:ce:15:ec:4d</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>75.699997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>False</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>2020-07-20 00:03:36.167959213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405182</th>\n",
       "      <td>1.595203e+09</td>\n",
       "      <td>00:0f:00:70:91:0a</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>75.300003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006247</td>\n",
       "      <td>False</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>2020-07-20 00:03:36.979521513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405183</th>\n",
       "      <td>1.595203e+09</td>\n",
       "      <td>b8:27:eb:bf:9d:51</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>48.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>False</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>2020-07-20 00:03:37.264312506</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405171 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ts             device        co   humidity  light       lpg  \\\n",
       "0       1.594512e+09  b8:27:eb:bf:9d:51  0.004956  51.000000      0  0.007651   \n",
       "1       1.594512e+09  00:0f:00:70:91:0a  0.002840  76.000000      0  0.005114   \n",
       "2       1.594512e+09  b8:27:eb:bf:9d:51  0.004976  50.900000      0  0.007673   \n",
       "3       1.594512e+09  1c:bf:ce:15:ec:4d  0.004403  76.800003      1  0.007023   \n",
       "4       1.594512e+09  b8:27:eb:bf:9d:51  0.004967  50.900000      0  0.007664   \n",
       "...              ...                ...       ...        ...    ...       ...   \n",
       "405179  1.595203e+09  00:0f:00:70:91:0a  0.003745  75.300003      0  0.006247   \n",
       "405180  1.595203e+09  b8:27:eb:bf:9d:51  0.005882  48.500000      0  0.008660   \n",
       "405181  1.595203e+09  1c:bf:ce:15:ec:4d  0.004540  75.699997      1  0.007181   \n",
       "405182  1.595203e+09  00:0f:00:70:91:0a  0.003745  75.300003      0  0.006247   \n",
       "405183  1.595203e+09  b8:27:eb:bf:9d:51  0.005914  48.400000      0  0.008695   \n",
       "\n",
       "        motion     smoke       temp                          time  \n",
       "0        False  0.020411  22.700000 2020-07-12 00:01:34.385974407  \n",
       "1        False  0.013275  19.700001 2020-07-12 00:01:34.735567570  \n",
       "2        False  0.020475  22.600000 2020-07-12 00:01:38.073572636  \n",
       "3        False  0.018628  27.000000 2020-07-12 00:01:39.589146137  \n",
       "4        False  0.020448  22.600000 2020-07-12 00:01:41.761234999  \n",
       "...        ...       ...        ...                           ...  \n",
       "405179   False  0.016437  19.200001 2020-07-20 00:03:33.162014961  \n",
       "405180   False  0.023301  22.200000 2020-07-20 00:03:33.576560736  \n",
       "405181   False  0.019076  26.600000 2020-07-20 00:03:36.167959213  \n",
       "405182   False  0.016437  19.200001 2020-07-20 00:03:36.979521513  \n",
       "405183   False  0.023400  22.200000 2020-07-20 00:03:37.264312506  \n",
       "\n",
       "[405171 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "#***\n",
    "data['time'] = pd.to_datetime(data['ts'], unit='s')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "#devices = labelencoder.fit_transform(data['device'])\n",
    "lights = labelencoder.fit_transform(data['light'])\n",
    "data['light']=lights\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>device</th>\n",
       "      <th>co</th>\n",
       "      <th>humidity</th>\n",
       "      <th>light</th>\n",
       "      <th>lpg</th>\n",
       "      <th>motion</th>\n",
       "      <th>smoke</th>\n",
       "      <th>temp</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "      <td>1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ts  device    co  humidity  light   lpg  motion  smoke  temp  time\n",
       "time                                                                      \n",
       "18     451     451   451       451    451   451     451    451   451   451\n",
       "19    1762    1762  1762      1762   1762  1762    1762   1762  1762  1762\n",
       "20     491     491   491       491    491   491     491    491   491   491\n",
       "21     297     297   297       297    297   297     297    297   297   297"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create feature matrix X and label vector y\n",
    "data_dev2=data[data['device']=='b8:27:eb:bf:9d:51']\n",
    "X = data_dev2.drop(['light','motion','time','device','ts'],axis=1)\n",
    "y = data_dev2[['light']].values\n",
    "\n",
    "#show in which hours the labelled 1 samples are distributed\n",
    "data_dev2.iloc[np.where(data_dev2[\"light\"]==1)].groupby(data_dev2[\"time\"].dt.hour).count()#plot.hist(column=[\"time\"], by=\"light\", figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>humidity</th>\n",
       "      <th>lpg</th>\n",
       "      <th>smoke</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004956</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.020411</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004976</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>0.020475</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004967</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.020448</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004976</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.007673</td>\n",
       "      <td>0.020475</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004970</td>\n",
       "      <td>50.9</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.020457</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405173</th>\n",
       "      <td>0.005901</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405176</th>\n",
       "      <td>0.005909</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.008689</td>\n",
       "      <td>0.023382</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405177</th>\n",
       "      <td>0.005877</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.023284</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405180</th>\n",
       "      <td>0.005882</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405183</th>\n",
       "      <td>0.005914</td>\n",
       "      <td>48.4</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187443 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              co  humidity       lpg     smoke  temp\n",
       "0       0.004956      51.0  0.007651  0.020411  22.7\n",
       "2       0.004976      50.9  0.007673  0.020475  22.6\n",
       "4       0.004967      50.9  0.007664  0.020448  22.6\n",
       "6       0.004976      50.9  0.007673  0.020475  22.6\n",
       "9       0.004970      50.9  0.007667  0.020457  22.6\n",
       "...          ...       ...       ...       ...   ...\n",
       "405173  0.005901      48.4  0.008681  0.023359  22.3\n",
       "405176  0.005909      48.4  0.008689  0.023382  22.3\n",
       "405177  0.005877      48.5  0.008654  0.023284  22.3\n",
       "405180  0.005882      48.5  0.008660  0.023301  22.2\n",
       "405183  0.005914      48.4  0.008695  0.023400  22.2\n",
       "\n",
       "[187443 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the feature matrix X\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create time series and labels\n",
    "# the times series is 17 elements long (i.e. it covers about 1 minute)\n",
    "# the predicted window comprises the next 9 elements (i.e. it covers about 30 sec)\n",
    "X_time_series,y,df_time_series=create_timeseries(data_dev2, X.values, 17,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training:  (12204, 17, 5)\n",
      "shape of validation:  (4456, 17, 5)\n",
      "shape of test:  (4165, 17, 5)\n",
      "#yes in training:  217\n",
      "%samples used in training:  73.25330132052821\n",
      "%yes in training:  1.778105539167486\n",
      "#yes in validation:  76\n",
      "%samples used in validation:  26.746698679471788\n",
      "%yes in validation:  1.7055655296229804\n",
      "#yes in test:  72\n",
      "%samples used in test:  20.0\n",
      "%yes in test:  1.7286914765906363\n"
     ]
    }
   ],
   "source": [
    "#***Construct training, validation and test sets \n",
    "y_train =[]\n",
    "X_train=[]\n",
    "for i in range(5204):\n",
    "    X_train.append(X_time_series[i,:,:])\n",
    "    y_train.append(y[i])\n",
    "for i in range(11475,11475+7000):\n",
    "    X_train.append(X_time_series[i,:,:])\n",
    "    y_train.append(y[i])\n",
    "    \n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "\n",
    "y_val =[]\n",
    "X_val=[]\n",
    "for i in range(5204,7310):\n",
    "    X_val.append(X_time_series[i,:,:])\n",
    "    y_val.append(y[i])\n",
    "for i in range(11475+7000,X_time_series.shape[0]):\n",
    "    X_val.append(X_time_series[i,:,:])\n",
    "    y_val.append(y[i])\n",
    "    \n",
    "X_val=np.array(X_val)\n",
    "y_val=np.array(y_val)\n",
    "\n",
    "X_test=X_time_series[7310:7310+4165,:,:]\n",
    "y_test=y[7310:7310+4165]\n",
    "\n",
    "print('shape of training: ', X_train.shape)\n",
    "print('shape of validation: ', X_val.shape)\n",
    "print('shape of test: ', X_test.shape)\n",
    "print('#yes in training: ', y_train.sum())\n",
    "print('%samples used in training: ',len(y_train)*100./(len(y_train)+len(y_val)))\n",
    "print('%yes in training: ', y_train.sum()*100./y_train.shape[0])\n",
    "print('#yes in validation: ', y_val.sum())\n",
    "print('%samples used in validation: ',len(y_val)*100./(len(y_train)+len(y_val)))\n",
    "print('%yes in validation: ', y_val.sum()*100./y_val.shape[0])\n",
    "print('#yes in test: ', y_test.sum())\n",
    "print('%samples used in test: ',len(y_test)*100./(len(y_train)+len(y_val)++len(y_test)))\n",
    "print('%yes in test: ', y_test.sum()*100./y_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12204, 17, 5)\n"
     ]
    }
   ],
   "source": [
    "#*** Initialize a scaler using the training data\n",
    "scaler = StandardScaler().fit(flatten(X_train))\n",
    "\n",
    "X_train_scaled = scale(X_train, scaler)\n",
    "X_val_scaled = scale(X_val, scaler)\n",
    "X_test_scaled = scale(X_test, scaler)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "\n",
    "TIMESTEPS = X_train_scaled.shape[1]\n",
    "N_FEATURES = X_train_scaled.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN1d - LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Convlayer (Conv1D)           (None, 16, 32)            352       \n",
      "_________________________________________________________________\n",
      "maxpooling (MaxPooling1D)    (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8, 16)             3136      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 13,889\n",
      "Trainable params: 13,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#***model: CNN1D-LSTM\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(TIMESTEPS, \n",
    "                       N_FEATURES), \n",
    "                name='input'))\n",
    "model.add(Conv1D(filters=32, \n",
    "                 kernel_size=2, \n",
    "                 activation='relu', \n",
    "                 name='Convlayer'))\n",
    "model.add(MaxPool1D(pool_size=2, \n",
    "                    name='maxpooling'))\n",
    "\n",
    "model.add((LSTM(32, return_sequences=True, dropout=0.5)))\n",
    "model.add((LSTM(16, return_sequences=True, dropout=0.5)))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(units=16, \n",
    "                activation='relu', \n",
    "                name='dense'))\n",
    "model.add(Dense(units=1, \n",
    "                activation='sigmoid', \n",
    "                name='output'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "run = False\n",
    "save = False\n",
    "\n",
    "optimizer = Adam(lr=1e-3, decay=1e-6)#adam\n",
    "model.compile(optimizer=optimizer,#'adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[\n",
    "                      'accuracy',\n",
    "                      tf.keras.metrics.Recall(),\n",
    "                      tm.F1Score(),\n",
    "                      tm.FalsePositiveRate()\n",
    "                  ])\n",
    "\n",
    "if run == True:\n",
    "    \n",
    "    if save == True:\n",
    "        checkpointer = ModelCheckpoint(\n",
    "                filepath=os.path.join('prediction', 'checkpoints', 'conv1d_lstm_lstm_100epoch_batch72_100epoch_lr1e-3_decay1e-6_telemetry' \\\n",
    "                    '.{epoch:03d}-{val_loss:.3f}.hdf5'), #_weight_class #13104_val_4320\n",
    "                verbose=1,\n",
    "                save_best_only=False)\n",
    "\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=72, validation_data=(X_val_scaled, y_val), \n",
    "                        callbacks=[checkpointer],verbose=2,shuffle=False)\n",
    "    # plot history\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization procedure to select optimal thresholds along epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computation of optimal thresholds on training by optimizing the tss and wtss\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "folder = 'prediction/checkpoints/'\n",
    "\n",
    "list_epochs = sorted(glob.glob(folder+'conv1d_lstm_lstm_100epoch_batch72_100epoch_lr1e-3_decay1e-6_telemetry*.hdf5'))\n",
    "file_name = 'conv1d_lstm_lstm_100epoch_batch72_100epoch_lr1e-3_decay1e-6_telemetry.npy'\n",
    "\n",
    "\n",
    "idx_start_train=[0,5024]\n",
    "idx_end_train=[5204,X_train_scaled.shape[0]]\n",
    "\n",
    "idx_start_val=[0,2106]\n",
    "idx_end_val=[2106,X_val_scaled.shape[0]]\n",
    "\n",
    "if run == True:\n",
    "    ####\n",
    "    threshold_opt_tss_weight=[]\n",
    "\n",
    "    wtss_train_dict_opt_tss_weight=[]\n",
    "    wtss_val_dict_opt_tss_weight=[]\n",
    "    whss_train_dict_opt_tss_weight=[]\n",
    "    whss_val_dict_opt_tss_weight=[]\n",
    "\n",
    "\n",
    "    threshold_opt_tss=[]\n",
    "\n",
    "\n",
    "    tss_train_dict_opt_tss=[]\n",
    "    tss_val_dict_opt_tss=[]\n",
    "    hss_train_dict_opt_tss=[]\n",
    "    hss_val_dict_opt_tss=[]\n",
    "    csi_train_dict_opt_tss=[]\n",
    "    csi_val_dict_opt_tss=[]\n",
    "\n",
    "    j=0\n",
    "\n",
    "    for file in list_epochs:\n",
    "        print(file)\n",
    "        model = load_model(file,compile=False)\n",
    "        pred_train = model.predict(X_train_scaled)\n",
    "        pred_val = model.predict(X_val_scaled)\n",
    "        pred_prob = pred_train.reshape(1,len(pred_train))\n",
    "        pred_prob = pred_prob[0]\n",
    "        pred_prob_val = pred_val.reshape(1,len(pred_val))\n",
    "        pred_prob_val = pred_prob_val[0]\n",
    "\n",
    "\n",
    "        #OPTIMIZE wTSS\n",
    "        threshold_tss_weight,max_tss=optimize_time_weighted_tss_split(pred_prob, y_train,idx_start_train,idx_end_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        threshold_opt_tss_weight.append(threshold_tss_weight)\n",
    "\n",
    "        #OPTIMIZE TSS\n",
    "        threshold_nss, metrics_training, nss_vector, threshold_tss, threshold_hss, threshold_tss_hss, max_tss_hss = optimize_threshold_skill_scores(pred_prob, y_train)\n",
    "\n",
    "\n",
    "        threshold_opt_tss.append(threshold_tss)\n",
    "\n",
    "\n",
    "\n",
    "        j = j + 1\n",
    "\n",
    "        #best wtss\n",
    "        cm, tss, hss, csi  = compute_weight_cm_tss_threshold_split(y_train, pred_prob,idx_start_train,idx_end_train,threshold_tss_weight)\n",
    "        wtss_train_dict_opt_tss_weight.append(tss)\n",
    "        whss_train_dict_opt_tss_weight.append(hss)\n",
    "        cm_val, tss_val, hss_val, csi_val = compute_weight_cm_tss_threshold_split(y_val, pred_prob_val,idx_start_val,idx_end_val,threshold_tss_weight)\n",
    "        wtss_val_dict_opt_tss_weight.append(tss_val)\n",
    "        whss_val_dict_opt_tss_weight.append(hss_val)\n",
    "        print ('threshold best tss                 \\t', threshold_tss_weight)\n",
    "\n",
    "\n",
    "        #best tss\n",
    "        cm, tss, hss, csi  = compute_cm_tss_threshold(y_train, pred_prob,threshold_tss)\n",
    "        tss_train_dict_opt_tss.append(tss)\n",
    "        hss_train_dict_opt_tss.append(hss)\n",
    "        cm_val, tss_val, hss_val, csi_val = compute_cm_tss_threshold(y_val, pred_prob_val,threshold_tss)\n",
    "        tss_val_dict_opt_tss.append(tss_val)\n",
    "        hss_val_dict_opt_tss.append(hss_val)\n",
    "        print ('threshold best tss                 \\t', threshold_tss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if save == True:\n",
    "        #save variables\n",
    "\n",
    "        folder_to_save = 'utilities/save_variables/'\n",
    "        ###########\n",
    "        file_tss_val_dict_tss = folder_to_save+'tss_val_optimize_TSS_'+file_name\n",
    "        file_hss_val_dict_tss = folder_to_save+'hss_val_optimize_TSS_'+file_name\n",
    "\n",
    "        file_tss_train_dict_tss = folder_to_save+'tss_train_optimize_TSS_'+file_name\n",
    "        file_hss_train_dict_tss = folder_to_save+'hss_train_optimize_TSS_'+file_name\n",
    "\n",
    "        file_threshold_dict_tss = folder_to_save+'thresholds_val_optimize_TSS_'+file_name\n",
    "\n",
    "        numpy.save(file_tss_val_dict_tss, tss_val_dict_opt_tss)\n",
    "        numpy.save(file_hss_val_dict_tss, hss_val_dict_opt_tss)\n",
    "\n",
    "        numpy.save(file_tss_train_dict_tss, tss_train_dict_opt_tss)\n",
    "        numpy.save(file_hss_train_dict_tss, hss_train_dict_opt_tss)\n",
    "\n",
    "        numpy.save(file_threshold_dict_tss, threshold_opt_tss)\n",
    "        ###########\n",
    "\n",
    "        ###########\n",
    "        file_wtss_val_dict_wtss = folder_to_save+'wtss_val_optimize_wTSS_'+file_name\n",
    "        file_whss_val_dict_wtss = folder_to_save+'whss_val_optimize_wTSS_'+file_name\n",
    "\n",
    "        file_wtss_train_dict_wtss = folder_to_save+'wtss_train_optimize_wTSS_'+file_name\n",
    "        file_whss_train_dict_wtss = folder_to_save+'whss_train_optimize_wTSS_'+file_name\n",
    "\n",
    "        file_threshold_dict_wtss = folder_to_save+'thresholds_val_optimize_wTSS_'+file_name\n",
    "\n",
    "        numpy.save(file_wtss_val_dict_wtss, wtss_val_dict_opt_tss_weight)\n",
    "        numpy.save(file_hss_val_dict_tss, whss_val_dict_opt_tss_weight)\n",
    "\n",
    "        numpy.save(file_wtss_train_dict_wtss, wtss_train_dict_opt_tss_weight)\n",
    "        numpy.save(file_whss_train_dict_wtss, whss_train_dict_opt_tss_weight)\n",
    "\n",
    "        numpy.save(file_threshold_dict_wtss, threshold_opt_tss_weight)\n",
    "        ###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***predict on test\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "folder = 'prediction/checkpoints/'\n",
    "folder_results = 'utilities/save_variables/'\n",
    "\n",
    "file_name = 'conv1d_lstm_lstm_100epoch_batch72_100epoch_lr1e-3_decay1e-6_telemetry.npy'\n",
    "list_epochs = sorted(glob.glob(folder+'conv1d_lstm_lstm_100epoch_batch72_100epoch_lr1e-3_decay1e-6_telemetry*.hdf5'))\n",
    "\n",
    "file_tss_val_dict_tss = folder_results+'tss_val_optimize_TSS_'+file_name\n",
    "file_threshold_dict_tss = folder_results+'thresholds_val_optimize_TSS_'+file_name\n",
    "file_wtss_val_dict_wtss = folder_results+'wtss_val_optimize_wTSS_'+file_name\n",
    "file_threshold_dict_wtss = folder_results+'thresholds_val_optimize_wTSS_'+file_name\n",
    "wtss_val_dict_opt_tss_weight=numpy.load(file_wtss_val_dict_wtss)\n",
    "tss_val_dict_opt_tss=numpy.load(file_tss_val_dict_tss)\n",
    "threshold_opt_tss=numpy.load(file_threshold_dict_tss,allow_pickle=True)\n",
    "threshold_opt_tss_weight=numpy.load(file_threshold_dict_wtss,allow_pickle=True)\n",
    "\n",
    "perc=0.98\n",
    "pred_median_pred_0_1 = predict_ensemble(tss_val_dict_opt_tss,perc,list_epochs,X_test_scaled,threshold_opt_tss)\n",
    "\n",
    "\n",
    "pred_median_pred_0_1_weight = predict_ensemble(wtss_val_dict_opt_tss_weight,perc,list_epochs,X_test_scaled,threshold_opt_tss_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test set with ensemble method\n",
      "Skill scores (optimization wtss strategy)\n",
      "[[3177  916]\n",
      " [   0   72]]\n",
      "tss =  0.7762\n",
      "hss =  0.1071\n",
      "csi =  0.0729\n",
      "Weighted Skill scores (optimization wtss strategy)\n",
      "[[3177. 1829.]\n",
      " [   0.   72.]]\n",
      "wtss =  0.6346\n",
      "whss =  0.0469\n",
      "wcsi =  0.0379\n",
      "Skill scores (optimization tss strategy)\n",
      "[[3135  958]\n",
      " [   0   72]]\n",
      "tss =  0.7659\n",
      "hss =  0.1016\n",
      "csi =  0.0699\n",
      "Weighted Skill scores (optimization tss strategy)\n",
      "[[3135. 1913.]\n",
      " [   0.   72.]]\n",
      "wtss =  0.6210\n",
      "whss =  0.0441\n",
      "wcsi =  0.0363\n"
     ]
    }
   ],
   "source": [
    "#***results on test\n",
    "print('Results on test set with ensemble method')\n",
    "cm_test, tss_test, hss_test, csi_test = compute_cm_tss(y_test, pred_median_pred_0_1_weight)\n",
    "print('Skill scores (optimization wtss strategy)')\n",
    "print(cm_test)\n",
    "print('tss = ','{:0.4f}'.format(tss_test))\n",
    "print('hss = ','{:0.4f}'.format(hss_test))\n",
    "print('csi = ','{:0.4f}'.format(csi_test))\n",
    "\n",
    "wcm_test, wtss_test, whss_test, wcsi_test = compute_weight_cm_tss(y_test, pred_median_pred_0_1_weight)\n",
    "print('Weighted Skill scores (optimization wtss strategy)')\n",
    "print(wcm_test)\n",
    "print('wtss = ','{:0.4f}'.format(wtss_test))\n",
    "print('whss = ','{:0.4f}'.format(whss_test))\n",
    "print('wcsi = ','{:0.4f}'.format(wcsi_test))\n",
    "\n",
    "\n",
    "cm_test, tss_test, hss_test, csi_test = compute_cm_tss(y_test, pred_median_pred_0_1)\n",
    "print('Skill scores (optimization tss strategy)')\n",
    "print(cm_test)\n",
    "print('tss = ','{:0.4f}'.format(tss_test))\n",
    "print('hss = ','{:0.4f}'.format(hss_test))\n",
    "print('csi = ','{:0.4f}'.format(csi_test))\n",
    "\n",
    "wcm_test, wtss_test, whss_test, wcsi_test = compute_weight_cm_tss(y_test, pred_median_pred_0_1)\n",
    "print('Weighted Skill scores (optimization tss strategy)')\n",
    "print(wcm_test)\n",
    "print('wtss = ','{:0.4f}'.format(wtss_test))\n",
    "print('whss = ','{:0.4f}'.format(whss_test))\n",
    "print('wcsi = ','{:0.4f}'.format(wcsi_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping experiments on IoT data stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Convlayer (Conv1D)           (None, 16, 32)            352       \n",
      "_________________________________________________________________\n",
      "maxpooling (MaxPooling1D)    (None, 8, 32)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8, 32)             8320      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 8, 16)             3136      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 13,889\n",
      "Trainable params: 13,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#EARLY STOPPING example\n",
    "import keras\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(TIMESTEPS, \n",
    "                       N_FEATURES), \n",
    "                name='input'))\n",
    "model.add(Conv1D(filters=32, \n",
    "                 kernel_size=2, \n",
    "                 activation='relu', \n",
    "                 name='Convlayer'))\n",
    "model.add(MaxPool1D(pool_size=2, \n",
    "                    name='maxpooling'))\n",
    "\n",
    "model.add((LSTM(32, return_sequences=True, dropout=0.5)))\n",
    "model.add((LSTM(16, return_sequences=True, dropout=0.5)))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(units=16, \n",
    "                activation='relu', \n",
    "                name='dense'))\n",
    "model.add(Dense(units=1, \n",
    "                activation='sigmoid', \n",
    "                name='output'))\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer,#'adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[\n",
    "                  'accuracy',\n",
    "                  tf.keras.metrics.Recall(),\n",
    "                  tm.F1Score(),\n",
    "                  tm.FalsePositiveRate()\n",
    "              ])\n",
    "# fit network\n",
    "if run == True:\n",
    "    patience=10\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss',\\\n",
    "                            patience=patience,mode='min')\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs=200, batch_size=72, validation_data=(X_val_scaled, y_val),\n",
    "                        callbacks=[callback],verbose=2, shuffle=False)\n",
    "    ep = len(model.history.history['loss'])\n",
    "    print('epochs:',ep)\n",
    "    # plot history\n",
    "    plt.plot(model.history.history['loss'], label='train')\n",
    "    plt.plot(model.history.history['val_loss'], label='val')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if save == True:\n",
    "        folder_save = 'prediction/'\n",
    "        model.save_weights(folder_save+'early_stop'+str(patience)+'_conv1d_lstm_lstm_200epoch_batch72_lr1e-3_decay1e-6_telemetry.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning of the 'patience' hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx best nss= (array([34]),)\n",
      "best NSS\n",
      "confusion matrix\n",
      "[[11094, 893], [76, 141]]\n",
      "false alarm ratio       \t 0.8636363636363636\n",
      "probability of detection\t 0.6497695852534562\n",
      "accuracy                \t 0.9205998033431662\n",
      "hss                     \t 0.20196258069670994\n",
      "tss                     \t 0.5752722131002903\n",
      "balance                 \t 0.0851063829787234\n",
      "csi                 \t 0.12702702702702703\n",
      "idx best tss= (array([10]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9371, 2616], [2, 215]]\n",
      "false alarm ratio       \t 0.9240551042034617\n",
      "probability of detection\t 0.9907834101382489\n",
      "accuracy                \t 0.7854801704359227\n",
      "hss                     \t 0.11173651145045511\n",
      "tss                     \t 0.7725469873468915\n",
      "balance                 \t 0.0007645259938837921\n",
      "csi                 \t 0.07589128132721497\n",
      "idx best hss= (array([52]),)\n",
      "best HSS\n",
      "confusion matrix\n",
      "[[11739, 248], [139, 78]]\n",
      "false alarm ratio       \t 0.7607361963190185\n",
      "probability of detection\t 0.35944700460829493\n",
      "accuracy                \t 0.9682890855457227\n",
      "hss                     \t 0.2717442926204665\n",
      "tss                     \t 0.3387579247718054\n",
      "balance                 \t 0.5604838709677419\n",
      "csi                 \t 0.16774193548387098\n",
      "idx best (tss+hss)/2 = (array([11]),)\n",
      "best (TSS+HSS)/2\n",
      "confusion matrix\n",
      "[[9462, 2525], [4, 213]]\n",
      "false alarm ratio       \t 0.9222059897735574\n",
      "probability of detection\t 0.9815668202764977\n",
      "accuracy                \t 0.7927728613569321\n",
      "hss                     \t 0.11500118367193385\n",
      "tss                     \t 0.7709219550057878\n",
      "balance                 \t 0.0015841584158415843\n",
      "csi                 \t 0.07768052516411379\n",
      "A: 0.23195566\n",
      "B: 2.8267024e-05\n",
      "MAX TSS: 0.6367012171504314\n",
      "idx best tss= (array([14]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9.76500000e+03 4.67333333e+03]\n",
      " [8.41666667e+00 2.04000000e+02]]\n",
      "false alarm ratio       \t 0.9581738655002734\n",
      "probability of detection\t 0.9603766182816791\n",
      "accuracy                \t 0.6804429807347747\n",
      "hss                     \t 0.05387083210082785\n",
      "tss                     \t 0.6367012171504314\n",
      "balance                 \t 0.0018009985734664773\n",
      "csi                 \t 0.0417540807450238\n",
      "idx best nss= (array([17]),)\n",
      "best NSS\n",
      "confusion matrix\n",
      "[[10516, 1471], [36, 181]]\n",
      "false alarm ratio       \t 0.8904358353510896\n",
      "probability of detection\t 0.8341013824884793\n",
      "accuracy                \t 0.8765158964274008\n",
      "hss                     \t 0.1675189391710454\n",
      "tss                     \t 0.7113851065228499\n",
      "balance                 \t 0.024473147518694765\n",
      "csi                 \t 0.10722748815165876\n",
      "idx best tss= (array([9]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9526, 2461], [1, 216]]\n",
      "false alarm ratio       \t 0.9193126634292118\n",
      "probability of detection\t 0.9953917050691244\n",
      "accuracy                \t 0.7982628646345461\n",
      "hss                     \t 0.12033735951965652\n",
      "tss                     \t 0.7900859571755731\n",
      "balance                 \t 0.0004063388866314506\n",
      "csi                 \t 0.08065720687079911\n",
      "idx best hss= (array([57]),)\n",
      "best HSS\n",
      "confusion matrix\n",
      "[[11833, 154], [155, 62]]\n",
      "false alarm ratio       \t 0.7129629629629629\n",
      "probability of detection\t 0.2857142857142857\n",
      "accuracy                \t 0.9746804326450345\n",
      "hss                     \t 0.27348577848983585\n",
      "tss                     \t 0.2728670345254978\n",
      "balance                 \t 1.0064935064935066\n",
      "csi                 \t 0.16711590296495957\n",
      "idx best (tss+hss)/2 = (array([10]),)\n",
      "best (TSS+HSS)/2\n",
      "confusion matrix\n",
      "[[9617, 2370], [3, 214]]\n",
      "false alarm ratio       \t 0.9171826625386997\n",
      "probability of detection\t 0.9861751152073732\n",
      "accuracy                \t 0.8055555555555556\n",
      "hss                     \t 0.12406576890145735\n",
      "tss                     \t 0.7884609248344693\n",
      "balance                 \t 0.0012658227848101266\n",
      "csi                 \t 0.08272129880170082\n",
      "A: 0.27505863\n",
      "B: 9.771053e-06\n",
      "MAX TSS: 0.6650523440322602\n",
      "idx best tss= (array([12]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9.91900000e+03 4.36608333e+03]\n",
      " [6.25000000e+00 2.07000000e+02]]\n",
      "false alarm ratio       \t 0.9547351349381343\n",
      "probability of detection\t 0.9706916764361079\n",
      "accuracy                \t 0.6984251063340614\n",
      "hss                     \t 0.06007834408319926\n",
      "tss                     \t 0.6650523440322602\n",
      "balance                 \t 0.0014314889393621294\n",
      "csi                 \t 0.045203086329887926\n",
      "idx best nss= (array([10]),)\n",
      "best NSS\n",
      "confusion matrix\n",
      "[[10312, 1675], [24, 193]]\n",
      "false alarm ratio       \t 0.8966809421841542\n",
      "probability of detection\t 0.8894009216589862\n",
      "accuracy                \t 0.8607833497214028\n",
      "hss                     \t 0.15831503524226143\n",
      "tss                     \t 0.7496662090536638\n",
      "balance                 \t 0.014328358208955224\n",
      "csi                 \t 0.10200845665961945\n",
      "idx best tss= (array([8]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9782, 2205], [5, 212]]\n",
      "false alarm ratio       \t 0.9122879602813405\n",
      "probability of detection\t 0.9769585253456221\n",
      "accuracy                \t 0.8189118321861685\n",
      "hss                     \t 0.1326688482297509\n",
      "tss                     \t 0.7930092469607051\n",
      "balance                 \t 0.0022675736961451248\n",
      "csi                 \t 0.0875309661436829\n",
      "idx best hss= (array([53, 54]),)\n",
      "best HSS\n",
      "confusion matrix\n",
      "[[11867, 120], [156, 61]]\n",
      "false alarm ratio       \t 0.6629834254143646\n",
      "probability of detection\t 0.28110599078341014\n",
      "accuracy                \t 0.9773844641101278\n",
      "hss                     \t 0.2951330483706864\n",
      "tss                     \t 0.27109514570123777\n",
      "balance                 \t 1.3\n",
      "csi                 \t 0.18100890207715134\n",
      "idx best (tss+hss)/2 = (array([8]),)\n",
      "best (TSS+HSS)/2\n",
      "confusion matrix\n",
      "[[9782, 2205], [5, 212]]\n",
      "false alarm ratio       \t 0.9122879602813405\n",
      "probability of detection\t 0.9769585253456221\n",
      "accuracy                \t 0.8189118321861685\n",
      "hss                     \t 0.1326688482297509\n",
      "tss                     \t 0.7930092469607051\n",
      "balance                 \t 0.0022675736961451248\n",
      "csi                 \t 0.0875309661436829\n",
      "A: 0.4070706\n",
      "B: 2.2608933e-06\n",
      "MAX TSS: 0.6662362643528396\n",
      "idx best tss= (array([8]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9.83300000e+03 4.53483333e+03]\n",
      " [3.91666667e+00 2.12000000e+02]]\n",
      "false alarm ratio       \t 0.9553386468171764\n",
      "probability of detection\t 0.981860285604014\n",
      "accuracy                \t 0.6887803205622698\n",
      "hss                     \t 0.058778956034552673\n",
      "tss                     \t 0.6662362643528396\n",
      "balance                 \t 0.0008636848101731049\n",
      "csi                 \t 0.04462453296847868\n",
      "idx best nss= (array([12]),)\n",
      "best NSS\n",
      "confusion matrix\n",
      "[[10710, 1277], [33, 184]]\n",
      "false alarm ratio       \t 0.8740588637919233\n",
      "probability of detection\t 0.847926267281106\n",
      "accuracy                \t 0.8926581448705343\n",
      "hss                     \t 0.1943636233348945\n",
      "tss                     \t 0.7413941908649885\n",
      "balance                 \t 0.025841816758026624\n",
      "csi                 \t 0.12315930388219545\n",
      "idx best tss= (array([8]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9848, 2139], [2, 215]]\n",
      "false alarm ratio       \t 0.9086661002548853\n",
      "probability of detection\t 0.9907834101382489\n",
      "accuracy                \t 0.8245657161586365\n",
      "hss                     \t 0.13922270340474116\n",
      "tss                     \t 0.8123400965485267\n",
      "balance                 \t 0.0009350163627863488\n",
      "csi                 \t 0.09125636672325976\n",
      "idx best hss= (array([53, 54]),)\n",
      "best HSS\n",
      "confusion matrix\n",
      "[[11849, 138], [154, 63]]\n",
      "false alarm ratio       \t 0.6865671641791045\n",
      "probability of detection\t 0.2903225806451613\n",
      "accuracy                \t 0.9760734185512947\n",
      "hss                     \t 0.28928181238355194\n",
      "tss                     \t 0.2788101088006631\n",
      "balance                 \t 1.1159420289855073\n",
      "csi                 \t 0.17746478873239438\n",
      "idx best (tss+hss)/2 = (array([8]),)\n",
      "best (TSS+HSS)/2\n",
      "confusion matrix\n",
      "[[9848, 2139], [2, 215]]\n",
      "false alarm ratio       \t 0.9086661002548853\n",
      "probability of detection\t 0.9907834101382489\n",
      "accuracy                \t 0.8245657161586365\n",
      "hss                     \t 0.13922270340474116\n",
      "tss                     \t 0.8123400965485267\n",
      "balance                 \t 0.0009350163627863488\n",
      "csi                 \t 0.09125636672325976\n",
      "A: 0.38380125\n",
      "B: 6.056463e-06\n",
      "MAX TSS: 0.6862814421770064\n",
      "idx best tss= (array([8]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[9.89400000e+03 4.41033333e+03]\n",
      " [1.16666667e+00 2.15000000e+02]]\n",
      "false alarm ratio       \t 0.9535168636494666\n",
      "probability of detection\t 0.994602929838088\n",
      "accuracy                \t 0.6961881477910541\n",
      "hss                     \t 0.06213832374893938\n",
      "tss                     \t 0.6862814421770064\n",
      "balance                 \t 0.00026453026982087535\n",
      "csi                 \t 0.04647141467632121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx best nss= (array([11]),)\n",
      "best NSS\n",
      "confusion matrix\n",
      "[[10919, 1068], [32, 185]]\n",
      "false alarm ratio       \t 0.8523543495610535\n",
      "probability of detection\t 0.8525345622119815\n",
      "accuracy                \t 0.9098656178302196\n",
      "hss                     \t 0.2283088176541862\n",
      "tss                     \t 0.7634380409806476\n",
      "balance                 \t 0.0299625468164794\n",
      "csi                 \t 0.14396887159533073\n",
      "idx best tss= (array([6]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[10279, 1708], [5, 212]]\n",
      "false alarm ratio       \t 0.8895833333333333\n",
      "probability of detection\t 0.9769585253456221\n",
      "accuracy                \t 0.8596361848574238\n",
      "hss                     \t 0.17195203739360773\n",
      "tss                     \t 0.8344708303427023\n",
      "balance                 \t 0.002927400468384075\n",
      "csi                 \t 0.11012987012987013\n",
      "idx best hss= (array([21]),)\n",
      "best HSS\n",
      "confusion matrix\n",
      "[[11639, 348], [109, 108]]\n",
      "false alarm ratio       \t 0.7631578947368421\n",
      "probability of detection\t 0.4976958525345622\n",
      "accuracy                \t 0.9625532612258276\n",
      "hss                     \t 0.30418490034418794\n",
      "tss                     \t 0.4686644017962624\n",
      "balance                 \t 0.3132183908045977\n",
      "csi                 \t 0.1911504424778761\n",
      "idx best (tss+hss)/2 = (array([9]),)\n",
      "best (TSS+HSS)/2\n",
      "confusion matrix\n",
      "[[10566, 1421], [14, 203]]\n",
      "false alarm ratio       \t 0.875\n",
      "probability of detection\t 0.9354838709677419\n",
      "accuracy                \t 0.8824156014421501\n",
      "hss                     \t 0.1952882053314223\n",
      "tss                     \t 0.8169387804530176\n",
      "balance                 \t 0.009852216748768473\n",
      "csi                 \t 0.12393162393162394\n",
      "A: 0.4433384\n",
      "B: 1.2628117e-06\n",
      "MAX TSS: 0.739799473240231\n",
      "idx best tss= (array([7]),)\n",
      "best TSS\n",
      "confusion matrix\n",
      "[[1.04560000e+04 3.30158333e+03]\n",
      " [4.33333333e+00 2.10000000e+02]]\n",
      "false alarm ratio       \t 0.9401979164194689\n",
      "probability of detection\t 0.9797822706065319\n",
      "accuracy                \t 0.7633884637636212\n",
      "hss                     \t 0.08630378101807758\n",
      "tss                     \t 0.739799473240231\n",
      "balance                 \t 0.0013125015775259353\n",
      "csi                 \t 0.05972837809011403\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load models obtained by applying early stopping with 5 different patiences (10,20,30,40,50)\n",
    "#For each model compute the best thresholds by optimizing TSS and wTSS\n",
    "# Choose models with the highest TSS and the highest wTSS in validation\n",
    "folder_path = 'prediction/'\n",
    "\n",
    "idx_start_train=[0,5024]\n",
    "idx_end_train=[5204,X_train_scaled.shape[0]]\n",
    "\n",
    "idx_start_val=[0,2106]\n",
    "idx_end_val=[2106,X_val_scaled.shape[0]]\n",
    "\n",
    "tss_opt_tss,wtss_opt_wtss, threshold_opt_tss, threshold_opt_wtss = select_best_patience_on_val(folder_path,X_train_scaled,y_train,idx_start_train,idx_end_train, X_val_scaled, y_val)\n",
    "\n",
    "    \n",
    "idx_patience_tss = numpy.argmax(tss_opt_tss)\n",
    "idx_patience_wtss = numpy.argmax(wtss_opt_wtss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on test set with Early Stopping\n",
      "Skill scores (optimization tss)\n",
      "[[3087 1006]\n",
      " [   0   72]]\n",
      "tss =  0.7542\n",
      "hss =  0.0959\n",
      "csi =  0.0668\n",
      "Weighted Skill scores (optimization tss)\n",
      "[[3087. 2009.]\n",
      " [   0.   72.]]\n",
      "wtss =  0.6058\n",
      "whss =  0.0411\n",
      "wcsi =  0.0346\n",
      "Skill scores (optimization wtss)\n",
      "[[3150  943]\n",
      " [   0   72]]\n",
      "tss =  0.7696\n",
      "hss =  0.1035\n",
      "csi =  0.0709\n",
      "Weighted Skill scores (optimization wtss)\n",
      "[[3150. 1883.]\n",
      " [   0.   72.]]\n",
      "wtss =  0.6259\n",
      "whss =  0.0451\n",
      "wcsi =  0.0368\n"
     ]
    }
   ],
   "source": [
    "#prediction on test set with early stopping strategy\n",
    "\n",
    "# threshold optimized on tss\n",
    "y_pred_test = predict(folder_path,TIMESTEPS,N_FEATURES,idx_patience_tss,X_test_scaled,threshold_opt_tss)\n",
    "\n",
    "print('Results on test set with Early Stopping')\n",
    "cm_test, tss_test, hss_test, csi_test = compute_cm_tss(y_test, y_pred_test)#_weight\n",
    "print('Skill scores (optimization tss)')\n",
    "print(cm_test)\n",
    "print('tss = ','{:0.4f}'.format(tss_test))\n",
    "print('hss = ','{:0.4f}'.format(hss_test))\n",
    "print('csi = ','{:0.4f}'.format(csi_test))\n",
    "wcm_test, wtss_test, whss_test, wcsi_test = compute_weight_cm_tss(y_test, y_pred_test)#_weight\n",
    "print('Weighted Skill scores (optimization tss)')\n",
    "print(wcm_test)\n",
    "print('wtss = ','{:0.4f}'.format(wtss_test))\n",
    "print('whss = ','{:0.4f}'.format(whss_test))\n",
    "print('wcsi = ','{:0.4f}'.format(wcsi_test))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# threshold optimized on wtss\n",
    "y_pred_test_weight = predict(folder_path,TIMESTEPS,N_FEATURES,idx_patience_wtss,X_test_scaled,threshold_opt_wtss)\n",
    "\n",
    "cm_test, tss_test, hss_test, csi_test = compute_cm_tss(y_test, y_pred_test_weight)#_weight\n",
    "print('Skill scores (optimization wtss)')\n",
    "print(cm_test)\n",
    "print('tss = ','{:0.4f}'.format(tss_test))\n",
    "print('hss = ','{:0.4f}'.format(hss_test))\n",
    "print('csi = ','{:0.4f}'.format(csi_test))\n",
    "wcm_test, wtss_test, whss_test, wcsi_test = compute_weight_cm_tss(y_test, y_pred_test_weight)#_weight\n",
    "print('Weighted Skill scores (optimization wtss)')\n",
    "print(wcm_test)\n",
    "print('wtss = ','{:0.4f}'.format(wtss_test))\n",
    "print('whss = ','{:0.4f}'.format(whss_test))\n",
    "print('wcsi = ','{:0.4f}'.format(wcsi_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
